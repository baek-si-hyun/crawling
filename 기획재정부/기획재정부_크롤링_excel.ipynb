{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "페이지 1 크롤링 중: https://www.moef.go.kr/nw/nes/nesdta.do?searchBbsId1=MOSFBBS_000000000028&menuNo=4010100&pageIndex=1\n",
      "페이지 2 크롤링 중: https://www.moef.go.kr/nw/nes/nesdta.do?searchBbsId1=MOSFBBS_000000000028&menuNo=4010100&pageIndex=2\n",
      "페이지 3 크롤링 중: https://www.moef.go.kr/nw/nes/nesdta.do?searchBbsId1=MOSFBBS_000000000028&menuNo=4010100&pageIndex=3\n",
      "페이지 4 크롤링 중: https://www.moef.go.kr/nw/nes/nesdta.do?searchBbsId1=MOSFBBS_000000000028&menuNo=4010100&pageIndex=4\n",
      "페이지 5 크롤링 중: https://www.moef.go.kr/nw/nes/nesdta.do?searchBbsId1=MOSFBBS_000000000028&menuNo=4010100&pageIndex=5\n",
      "\n",
      "새로운 데이터 50개를 수집하였습니다.\n",
      "중복을 제거한 후 총 50개의 데이터가 '기획재정부.xlsx'에 저장되었습니다.\n",
      "\n",
      "하이퍼링크가 추가된 Excel 파일 '기획재정부.xlsx'을 생성하였습니다.\n"
     ]
    }
   ],
   "source": [
    "# 필요한 라이브러리 설치 (한 번만 실행하면 됩니다)\n",
    "# !pip install playwright nest_asyncio pandas openpyxl\n",
    "# !playwright install\n",
    "\n",
    "# nest_asyncio 적용\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# 라이브러리 임포트\n",
    "import asyncio\n",
    "from playwright.async_api import async_playwright\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import os\n",
    "import urllib.parse\n",
    "from openpyxl.utils import get_column_letter\n",
    "from openpyxl.styles import Font\n",
    "from openpyxl import load_workbook\n",
    "import html  # HTML 엔티티 디코딩을 위해 추가\n",
    "\n",
    "async def main():\n",
    "    data_list = []\n",
    "\n",
    "    # 검색어 입력 받기\n",
    "    search_keyword = input(\"검색어를 입력하세요 (없으면 엔터): \").strip()\n",
    "\n",
    "    # 페이지 수 설정 (한 페이지당 5개씩)\n",
    "    select_page_num = 5  # 페이지 번호는 1부터 시작하므로 1~5페이지를 의미합니다.\n",
    "\n",
    "    # 검색어에 따라 Excel 파일 이름 설정\n",
    "    if search_keyword:\n",
    "        encoded_keyword = urllib.parse.quote(search_keyword)\n",
    "        excel_file = f'기획재정부_{search_keyword}.xlsx'\n",
    "    else:\n",
    "        excel_file = '기획재정부.xlsx'\n",
    "\n",
    "    # 기존 데이터 로드\n",
    "    if os.path.exists(excel_file):\n",
    "        existing_df = pd.read_excel(excel_file)\n",
    "    else:\n",
    "        existing_df = pd.DataFrame(columns=['title', 'depart', 'date', 'download_link', 'preview_link'])\n",
    "\n",
    "    async with async_playwright() as p:\n",
    "        browser = await p.chromium.launch(headless=True)  # GUI를 표시하지 않음\n",
    "        page = await browser.new_page()\n",
    "\n",
    "        # 1단계: 목록 페이지에서 데이터 수집\n",
    "        for page_num in range(1, select_page_num + 1):\n",
    "            if search_keyword:\n",
    "                if page_num == 1:\n",
    "                    # 첫 번째 페이지 URL (검색어 포함, pageIndex 없음)\n",
    "                    url = f\"https://www.moef.go.kr/nw/nes/nesdta.do?searchBbsId1=MOSFBBS_000000000028&menuNo=4010100&searchKeyword3={encoded_keyword}&searchCondition3=0&searchSilDeptId1=&kwd1=\"\n",
    "                else:\n",
    "                    # 두 번째 페이지부터 URL (검색어 및 pageIndex 포함)\n",
    "                    url = f\"https://www.moef.go.kr/nw/nes/nesdta.do?searchBbsId1=MOSFBBS_000000000028&menuNo=4010100&pageIndex={page_num}&searchKeyword3={encoded_keyword}&searchCondition3=0&searchSilDeptId1=&kwd1=\"\n",
    "            else:\n",
    "                # 검색어가 없을 때의 URL\n",
    "                url = f\"https://www.moef.go.kr/nw/nes/nesdta.do?searchBbsId1=MOSFBBS_000000000028&menuNo=4010100&pageIndex={page_num}\"\n",
    "\n",
    "            print(f\"페이지 {page_num} 크롤링 중: {url}\")\n",
    "            try:\n",
    "                await page.goto(url)\n",
    "                await page.wait_for_timeout(1000)  # 1초 지연\n",
    "\n",
    "                # 페이지의 HTML 가져오기\n",
    "                content = await page.content()\n",
    "                soup = BeautifulSoup(content, 'html.parser')\n",
    "\n",
    "                # 리스트 아이템 선택\n",
    "                list_items = soup.find_all('li')\n",
    "\n",
    "                # 페이지 내 데이터 수 카운트 초기화\n",
    "                page_data_count = 0\n",
    "\n",
    "                for item in list_items:\n",
    "                    # 제목과 href를 포함한 a 태그 찾기\n",
    "                    h3_tag = item.find('h3')\n",
    "                    if h3_tag:\n",
    "                        a_tag = h3_tag.find('a')\n",
    "                        if a_tag:\n",
    "                            title = a_tag.get_text(strip=True)\n",
    "\n",
    "                            # href 추출 및 절대 URL로 변환 (공백 제거, HTML 엔티티 디코딩)\n",
    "                            href = a_tag.get('href', '').strip()\n",
    "                            href = html.unescape(href)  # HTML 엔티티 디코딩\n",
    "                            if href.startswith('/'):\n",
    "                                href = 'https://www.moef.go.kr' + href\n",
    "                            elif href.startswith('dtl.jsp'):\n",
    "                                href = 'https://www.moef.go.kr/' + href\n",
    "                            else:\n",
    "                                href = 'https://www.moef.go.kr' + href\n",
    "\n",
    "                            # 날짜 추출\n",
    "                            date_span = item.find('span', class_='date')\n",
    "                            if date_span:\n",
    "                                date = date_span.get_text(strip=True)\n",
    "                            else:\n",
    "                                date = None\n",
    "\n",
    "                            # 과 추출\n",
    "                            depart_span = item.find('span', class_='depart')\n",
    "                            if depart_span:\n",
    "                                depart = depart_span.get_text(strip=True)\n",
    "                            else:\n",
    "                                depart = None\n",
    "\n",
    "                            # 첨부파일 다운로드 링크 추출\n",
    "                            download_link_tag = item.find('a', class_='icoFile fileDown')\n",
    "                            if download_link_tag:\n",
    "                                download_link = download_link_tag.get('href', '').strip()\n",
    "                                download_link = html.unescape(download_link)  # HTML 엔티티 디코딩\n",
    "                                if download_link.startswith('/'):\n",
    "                                    download_link = 'https://www.moef.go.kr' + download_link\n",
    "                                elif download_link.startswith('dtl.jsp'):\n",
    "                                    download_link = 'https://www.moef.go.kr/' + download_link\n",
    "                                else:\n",
    "                                    download_link = 'https://www.moef.go.kr' + download_link\n",
    "                            else:\n",
    "                                download_link = None\n",
    "\n",
    "                            # 첨부파일 미리보기 링크 추출\n",
    "                            preview_link_tag = item.find('a', class_='icoFile fileView')\n",
    "                            if preview_link_tag:\n",
    "                                preview_link = preview_link_tag.get('href', '').strip()\n",
    "                                preview_link = html.unescape(preview_link)  # HTML 엔티티 디코딩\n",
    "                                if preview_link.startswith('/'):\n",
    "                                    preview_link = 'https://www.moef.go.kr' + preview_link\n",
    "                                elif preview_link.startswith('dtl.jsp'):\n",
    "                                    preview_link = 'https://www.moef.go.kr/' + preview_link\n",
    "                                else:\n",
    "                                    preview_link = 'https://www.moef.go.kr' + preview_link\n",
    "                            else:\n",
    "                                preview_link = None\n",
    "\n",
    "                            data = {\n",
    "                                'title': title,\n",
    "                                'depart': depart,\n",
    "                                'date': date,\n",
    "                                'download_link': download_link,\n",
    "                                'preview_link': preview_link\n",
    "                            }\n",
    "\n",
    "                            data_list.append(data)\n",
    "                            page_data_count += 1\n",
    "\n",
    "                # 데이터가 하나도 수집되지 않은 페이지가 나오면 반복문 종료\n",
    "                if page_data_count == 0:\n",
    "                    print(f\"페이지 {page_num}에 데이터가 없습니다. 더 이상의 페이지가 없다고 판단하여 크롤링을 종료합니다.\")\n",
    "                    break\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"페이지 {page_num} 크롤링 중 오류 발생: {e}\")\n",
    "                continue\n",
    "\n",
    "        await browser.close()\n",
    "\n",
    "        # 데이터가 수집되지 않은 경우 Excel 저장 단계 건너뛰기\n",
    "        if not data_list:\n",
    "            print(\"\\n크롤링한 데이터가 없습니다. Excel 파일을 생성하지 않습니다.\")\n",
    "            return\n",
    "\n",
    "        # 2단계: 데이터 저장 (Excel 파일로) 및 열 너비 조정\n",
    "        try:\n",
    "            # 새로운 데이터프레임 생성\n",
    "            new_df = pd.DataFrame(data_list)\n",
    "\n",
    "            # 기존 데이터와 새로운 데이터 병합\n",
    "            combined_df = pd.concat([existing_df, new_df], ignore_index=True)\n",
    "\n",
    "            # 중복 제거 ('title'과 'date'가 모두 동일한 경우 중복으로 간주)\n",
    "            combined_df.drop_duplicates(subset=['title', 'date'], keep='first', inplace=True)\n",
    "\n",
    "            # Excel 파일로 저장 (열 너비 자동 조정)\n",
    "            with pd.ExcelWriter(excel_file, engine='openpyxl') as writer:\n",
    "                combined_df.to_excel(writer, index=False, sheet_name='Sheet1')\n",
    "                workbook = writer.book\n",
    "                worksheet = writer.sheets['Sheet1']\n",
    "\n",
    "                # 각 열의 최대 길이를 계산하여 열 너비를 설정\n",
    "                for i, column in enumerate(combined_df.columns, 1):\n",
    "                    # 열의 최대 길이 계산\n",
    "                    max_length = combined_df[column].astype(str).map(len).max()\n",
    "                    # 열 제목의 길이와 비교하여 더 큰 값 선택\n",
    "                    max_length = max(max_length, len(column)) + 2  # 여유 공간 추가\n",
    "                    # 열 번호를 열 문자로 변환\n",
    "                    column_letter = get_column_letter(i)\n",
    "                    # 열 너비 설정\n",
    "                    worksheet.column_dimensions[column_letter].width = max_length\n",
    "\n",
    "            print(f\"\\n새로운 데이터 {len(new_df)}개를 수집하였습니다.\")\n",
    "            print(f\"중복을 제거한 후 총 {len(combined_df)}개의 데이터가 '{excel_file}'에 저장되었습니다.\")\n",
    "\n",
    "            # 하이퍼링크 설정을 위해 워크북 다시 로드\n",
    "            wb = load_workbook(excel_file)\n",
    "            ws = wb['Sheet1']\n",
    "\n",
    "            # 'download_link'와 'preview_link' 컬럼 인덱스 찾기\n",
    "            try:\n",
    "                download_col = combined_df.columns.get_loc('download_link') + 1  # 1부터 시작\n",
    "                preview_col = combined_df.columns.get_loc('preview_link') + 1\n",
    "            except ValueError as ve:\n",
    "                print(f\"컬럼을 찾을 수 없습니다: {ve}\")\n",
    "                return\n",
    "\n",
    "            # 하이퍼링크 설정\n",
    "            for row in range(2, len(combined_df) + 2):  # 헤더 제외\n",
    "                # 다운로드 링크 하이퍼링크 설정\n",
    "                download_cell = ws.cell(row=row, column=download_col)\n",
    "                if download_cell.value and isinstance(download_cell.value, str) and download_cell.value.startswith('http'):\n",
    "                    download_cell.hyperlink = download_cell.value\n",
    "                    download_cell.font = Font(color='0000FF', underline='single')\n",
    "\n",
    "                # 미리보기 링크 하이퍼링크 설정\n",
    "                preview_cell = ws.cell(row=row, column=preview_col)\n",
    "                if preview_cell.value and isinstance(preview_cell.value, str) and preview_cell.value.startswith('http'):\n",
    "                    preview_cell.hyperlink = preview_cell.value\n",
    "                    preview_cell.font = Font(color='0000FF', underline='single')\n",
    "\n",
    "            # 워크북 저장\n",
    "            wb.save(excel_file)\n",
    "\n",
    "            print(f\"\\n하이퍼링크가 추가된 Excel 파일 '{excel_file}'을 생성하였습니다.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"엑셀 파일 저장 중 오류 발생: {e}\")\n",
    "\n",
    "# 주피터 노트북에서 비동기 함수 실행\n",
    "await main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
