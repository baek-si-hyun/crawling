{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "페이지 1 크롤링 중: https://www.seoul.go.kr/news/news_report.do#list/1/srchBeginDt=20231012&srchEndDt=20241011&cntPerPage=10\n",
      "페이지 2 크롤링 중: https://www.seoul.go.kr/news/news_report.do#list/2/srchBeginDt=20231012&srchEndDt=20241011&cntPerPage=10\n",
      "페이지 3 크롤링 중: https://www.seoul.go.kr/news/news_report.do#list/3/srchBeginDt=20231012&srchEndDt=20241011&cntPerPage=10\n",
      "페이지 4 크롤링 중: https://www.seoul.go.kr/news/news_report.do#list/4/srchBeginDt=20231012&srchEndDt=20241011&cntPerPage=10\n",
      "페이지 5 크롤링 중: https://www.seoul.go.kr/news/news_report.do#list/5/srchBeginDt=20231012&srchEndDt=20241011&cntPerPage=10\n",
      "\n",
      "상세 페이지에서 다운로드 링크와 미리보기 링크를 수집 중입니다...\n",
      "\n",
      "상세 페이지 1/50: https://www.seoul.go.kr/news/news_report.do#view/420702\n",
      "상세 페이지 2/50: https://www.seoul.go.kr/news/news_report.do#view/420701\n",
      "상세 페이지 3/50: https://www.seoul.go.kr/news/news_report.do#view/420696\n",
      "상세 페이지 4/50: https://www.seoul.go.kr/news/news_report.do#view/420682\n",
      "상세 페이지 5/50: https://www.seoul.go.kr/news/news_report.do#view/420681\n",
      "상세 페이지 6/50: https://www.seoul.go.kr/news/news_report.do#view/420680\n",
      "상세 페이지 7/50: https://www.seoul.go.kr/news/news_report.do#view/420679\n",
      "상세 페이지 8/50: https://www.seoul.go.kr/news/news_report.do#view/420678\n",
      "상세 페이지 9/50: https://www.seoul.go.kr/news/news_report.do#view/420659\n",
      "상세 페이지 10/50: https://www.seoul.go.kr/news/news_report.do#view/420658\n",
      "상세 페이지 11/50: https://www.seoul.go.kr/news/news_report.do#view/420657\n",
      "상세 페이지 12/50: https://www.seoul.go.kr/news/news_report.do#view/420656\n",
      "상세 페이지 13/50: https://www.seoul.go.kr/news/news_report.do#view/420655\n",
      "상세 페이지 14/50: https://www.seoul.go.kr/news/news_report.do#view/420654\n",
      "상세 페이지 15/50: https://www.seoul.go.kr/news/news_report.do#view/420631\n",
      "상세 페이지 16/50: https://www.seoul.go.kr/news/news_report.do#view/420609\n",
      "상세 페이지 17/50: https://www.seoul.go.kr/news/news_report.do#view/420608\n",
      "상세 페이지 18/50: https://www.seoul.go.kr/news/news_report.do#view/420607\n",
      "상세 페이지 19/50: https://www.seoul.go.kr/news/news_report.do#view/420606\n",
      "상세 페이지 20/50: https://www.seoul.go.kr/news/news_report.do#view/420605\n",
      "상세 페이지 21/50: https://www.seoul.go.kr/news/news_report.do#view/420702\n",
      "상세 페이지 22/50: https://www.seoul.go.kr/news/news_report.do#view/420701\n",
      "상세 페이지 23/50: https://www.seoul.go.kr/news/news_report.do#view/420696\n",
      "상세 페이지 24/50: https://www.seoul.go.kr/news/news_report.do#view/420682\n",
      "상세 페이지 25/50: https://www.seoul.go.kr/news/news_report.do#view/420681\n",
      "상세 페이지 26/50: https://www.seoul.go.kr/news/news_report.do#view/420680\n",
      "상세 페이지 27/50: https://www.seoul.go.kr/news/news_report.do#view/420679\n",
      "상세 페이지 28/50: https://www.seoul.go.kr/news/news_report.do#view/420678\n",
      "상세 페이지 29/50: https://www.seoul.go.kr/news/news_report.do#view/420659\n",
      "상세 페이지 30/50: https://www.seoul.go.kr/news/news_report.do#view/420658\n",
      "상세 페이지 31/50: https://www.seoul.go.kr/news/news_report.do#view/420559\n",
      "상세 페이지 32/50: https://www.seoul.go.kr/news/news_report.do#view/420558\n",
      "상세 페이지 33/50: https://www.seoul.go.kr/news/news_report.do#view/420557\n",
      "상세 페이지 34/50: https://www.seoul.go.kr/news/news_report.do#view/420556\n",
      "상세 페이지 35/50: https://www.seoul.go.kr/news/news_report.do#view/420526\n",
      "상세 페이지 36/50: https://www.seoul.go.kr/news/news_report.do#view/420502\n",
      "상세 페이지 37/50: https://www.seoul.go.kr/news/news_report.do#view/420501\n",
      "상세 페이지 38/50: https://www.seoul.go.kr/news/news_report.do#view/420500\n",
      "상세 페이지 39/50: https://www.seoul.go.kr/news/news_report.do#view/420499\n",
      "상세 페이지 40/50: https://www.seoul.go.kr/news/news_report.do#view/420498\n",
      "상세 페이지 41/50: https://www.seoul.go.kr/news/news_report.do#view/420483\n",
      "상세 페이지 42/50: https://www.seoul.go.kr/news/news_report.do#view/420482\n",
      "상세 페이지 43/50: https://www.seoul.go.kr/news/news_report.do#view/420481\n",
      "상세 페이지 44/50: https://www.seoul.go.kr/news/news_report.do#view/420480\n",
      "상세 페이지 45/50: https://www.seoul.go.kr/news/news_report.do#view/420479\n",
      "상세 페이지 46/50: https://www.seoul.go.kr/news/news_report.do#view/420437\n",
      "상세 페이지 47/50: https://www.seoul.go.kr/news/news_report.do#view/420419\n",
      "상세 페이지 48/50: https://www.seoul.go.kr/news/news_report.do#view/420418\n",
      "상세 페이지 49/50: https://www.seoul.go.kr/news/news_report.do#view/420417\n",
      "상세 페이지 50/50: https://www.seoul.go.kr/news/news_report.do#view/420416\n",
      "\n",
      "새로운 데이터 50개를 수집하였습니다.\n",
      "중복을 제거한 후 총 40개의 데이터가 '서울시청.xlsx'에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# nest_asyncio 적용\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# 라이브러리 임포트\n",
    "import asyncio\n",
    "from playwright.async_api import async_playwright\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import os\n",
    "import urllib.parse\n",
    "from openpyxl.utils import get_column_letter\n",
    "from openpyxl.styles import Font\n",
    "from openpyxl import load_workbook\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "async def main():\n",
    "    # 데이터 저장을 위한 리스트 초기화\n",
    "    data_list = []\n",
    "\n",
    "    # 검색어 입력 받기\n",
    "    search_keyword = input(\"검색어를 입력하세요 (없으면 엔터): \").strip()\n",
    "\n",
    "    # 페이지 수 설정\n",
    "    max_page_num = 5  # 1부터 5페이지까지\n",
    "\n",
    "    # 오늘 날짜와 1년 전 날짜 계산 (YYYYMMDD 형식)\n",
    "    today = datetime.today().strftime('%Y%m%d')\n",
    "    one_year_ago = (datetime.today() - timedelta(days=365)).strftime('%Y%m%d')\n",
    "\n",
    "    # 검색어에 따라 Excel 파일 이름 설정\n",
    "    if search_keyword:\n",
    "        excel_file = f'서울시청_{search_keyword}.xlsx'\n",
    "    else:\n",
    "        excel_file = '서울시청.xlsx'\n",
    "\n",
    "    # 기존 데이터 로드\n",
    "    if os.path.exists(excel_file):\n",
    "        existing_df = pd.read_excel(excel_file)\n",
    "    else:\n",
    "        existing_df = pd.DataFrame(columns=['title', 'department', 'date', 'download_link', 'preview_link'])\n",
    "\n",
    "    async with async_playwright() as p:\n",
    "        browser = await p.chromium.launch(headless=True)  # GUI를 표시하지 않음\n",
    "        page = await browser.new_page()\n",
    "\n",
    "        # 1단계: 목록 페이지에서 데이터 수집\n",
    "        for page_num in range(1, max_page_num + 1):\n",
    "            if search_keyword:\n",
    "                # 검색어가 있을 경우 URL 구성\n",
    "                url = f\"https://www.seoul.go.kr/news/news_report.do#list/{page_num}/srchBeginDt={one_year_ago}&srchEndDt={today}&cntPerPage=10&srchKey=sj&srchText={urllib.parse.quote(search_keyword)}\"\n",
    "            else:\n",
    "                # 검색어가 없을 경우 URL 구성 (srchKey와 srchText 파라미터 제외)\n",
    "                url = f\"https://www.seoul.go.kr/news/news_report.do#list/{page_num}/srchBeginDt={one_year_ago}&srchEndDt={today}&cntPerPage=10\"\n",
    "\n",
    "            print(f\"페이지 {page_num} 크롤링 중: {url}\")\n",
    "            try:\n",
    "                # 기본 페이지 로드\n",
    "                await page.goto('https://www.seoul.go.kr/news/news_report.do')\n",
    "                # 해시가 포함된 URL로 이동\n",
    "                await page.evaluate(f\"window.location.href = '{url}'\")\n",
    "                # 페이지가 완전히 로드될 때까지 대기\n",
    "                await page.wait_for_load_state('networkidle')\n",
    "                # tbody 요소가 로드될 때까지 대기\n",
    "                await page.wait_for_selector('tbody')\n",
    "\n",
    "                # 페이지의 HTML 가져오기\n",
    "                content = await page.content()\n",
    "                soup = BeautifulSoup(content, 'html.parser')\n",
    "\n",
    "                # tbody 내의 tr 태그 선택\n",
    "                tbody = soup.find('tbody')\n",
    "                if not tbody:\n",
    "                    print(f\"페이지 {page_num}에서 tbody를 찾을 수 없습니다.\")\n",
    "                    continue\n",
    "\n",
    "                rows = tbody.find_all('tr')\n",
    "\n",
    "                # 페이지 내 데이터 수 카운트 초기화\n",
    "                page_data_count = 0\n",
    "\n",
    "                for row in rows:\n",
    "                    # 제목, 담당부서, 날짜, data-code 추출\n",
    "                    a_tag = row.find('a', attrs={'data-code': True})\n",
    "                    if a_tag:\n",
    "                        title = a_tag.get_text(strip=True)\n",
    "                        data_code = a_tag.get('data-code', '').strip()\n",
    "                        if not data_code:\n",
    "                            continue\n",
    "\n",
    "                        # 담당부서 추출 (세 번째 td)\n",
    "                        department_td = row.find_all('td')[2] if len(row.find_all('td')) > 2 else None\n",
    "                        department = department_td.get_text(strip=True) if department_td else ''\n",
    "\n",
    "                        # 날짜 추출 (네 번째 td)\n",
    "                        date_td = row.find_all('td')[3] if len(row.find_all('td')) > 3 else None\n",
    "                        date = date_td.get_text(strip=True) if date_td else ''\n",
    "\n",
    "                        # 상세 페이지 URL 구성\n",
    "                        href = f\"https://www.seoul.go.kr/news/news_report.do#view/{data_code}\"\n",
    "\n",
    "                        # 데이터 저장\n",
    "                        data = {\n",
    "                            'title': title,\n",
    "                            'department': department,\n",
    "                            'date': date,\n",
    "                            'data_code': data_code,\n",
    "                            'href': href,\n",
    "                            'download_link': None,\n",
    "                            'preview_link': None\n",
    "                        }\n",
    "\n",
    "                        data_list.append(data)\n",
    "                        page_data_count += 1\n",
    "\n",
    "                # 데이터가 하나도 수집되지 않은 페이지가 나오면 반복문 종료\n",
    "                if page_data_count == 0:\n",
    "                    print(f\"페이지 {page_num}에 데이터가 없습니다. 더 이상의 페이지가 없다고 판단하여 크롤링을 종료합니다.\")\n",
    "                    break\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"페이지 {page_num} 크롤링 중 오류 발생: {e}\")\n",
    "                continue\n",
    "\n",
    "        # 목록 페이지 크롤링이 끝났으므로 브라우저 닫기\n",
    "        await browser.close()\n",
    "\n",
    "        # 데이터가 수집되지 않은 경우 Excel 저장 단계 건너뛰기\n",
    "        if not data_list:\n",
    "            print(\"\\n크롤링한 데이터가 없습니다. Excel 파일을 생성하지 않습니다.\")\n",
    "            return\n",
    "\n",
    "        # 2단계: 상세 페이지에서 다운로드 링크와 미리보기 링크 수집\n",
    "        print(\"\\n상세 페이지에서 다운로드 링크와 미리보기 링크를 수집 중입니다...\\n\")\n",
    "\n",
    "        # 상세 페이지 수집을 위해 브라우저 재실행\n",
    "        browser = await p.chromium.launch(headless=True)\n",
    "        page = await browser.new_page()\n",
    "\n",
    "        for idx, entry in enumerate(data_list, start=1):\n",
    "            href = entry['href']\n",
    "            data_code = entry['data_code']\n",
    "            print(f\"상세 페이지 {idx}/{len(data_list)}: {href}\")\n",
    "            try:\n",
    "                await page.goto('https://www.seoul.go.kr/news/news_report.do')\n",
    "                await page.evaluate(f\"window.location.href = '{href}'\")\n",
    "                await page.wait_for_load_state('networkidle')\n",
    "                # 상세 페이지의 특정 요소가 로드될 때까지 대기\n",
    "                await page.wait_for_selector('thead')\n",
    "\n",
    "                # 상세 페이지의 HTML 가져오기\n",
    "                detail_content = await page.content()\n",
    "                detail_soup = BeautifulSoup(detail_content, 'html.parser')\n",
    "\n",
    "                # 첨부파일 정보 추출\n",
    "                download_links = []\n",
    "                preview_links = []\n",
    "\n",
    "                # thead 내의 첨부파일 관련 tr 태그 찾기\n",
    "                tr_tags = detail_soup.select('thead tr')\n",
    "\n",
    "                for tr in tr_tags:\n",
    "                    # 다운로드 링크 추출\n",
    "                    p_tag = tr.find('p', attrs={'data-srvcid': True})\n",
    "                    if p_tag:\n",
    "                        data_attributes = p_tag.attrs\n",
    "                        upper_no = data_attributes.get('data-upperno', '')\n",
    "                        # 다운로드 링크 구성\n",
    "                        download_link = f\"https://seoulboard.seoul.go.kr/comm/getFile?srvcId=BBSTY1&upperNo={upper_no}&fileTy=ATTACH&fileNo=2&bbsNo=158\"\n",
    "                        download_links.append(download_link)\n",
    "\n",
    "                        # 미리보기 링크 추출 (버튼의 data-url 속성 사용)\n",
    "                        preview_button = tr.find('button', {'data-type': 'preview'})\n",
    "                        if preview_button:\n",
    "                            preview_link = preview_button.get('data-url', '')\n",
    "                            preview_links.append(preview_link)\n",
    "\n",
    "                # 첫 번째 다운로드 링크와 미리보기 링크 저장\n",
    "                entry['download_link'] = download_links[0] if download_links else None\n",
    "                entry['preview_link'] = preview_links[0] if preview_links else None\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"상세 페이지 {href} 크롤링 중 오류 발생: {e}\")\n",
    "                data_list[idx - 1]['download_link'] = None\n",
    "                data_list[idx - 1]['preview_link'] = None\n",
    "                continue\n",
    "\n",
    "        # 상세 페이지 크롤링이 끝났으므로 브라우저 닫기\n",
    "        await browser.close()\n",
    "\n",
    "    # 3단계: 데이터 저장 (Excel 파일로) 및 열 너비 조정\n",
    "    try:\n",
    "        # 'data_code'와 'href'를 제외한 데이터만 추출\n",
    "        data_without_href = [\n",
    "            {\n",
    "                'title': d['title'],\n",
    "                'department': d['department'],\n",
    "                'date': d['date'],\n",
    "                'download_link': d['download_link'],\n",
    "                'preview_link': d['preview_link']\n",
    "            }\n",
    "            for d in data_list\n",
    "        ]\n",
    "\n",
    "        # 새로운 데이터프레임 생성\n",
    "        new_df = pd.DataFrame(data_without_href)\n",
    "\n",
    "        # 기존 데이터와 새로운 데이터 병합\n",
    "        combined_df = pd.concat([existing_df, new_df], ignore_index=True)\n",
    "\n",
    "        # 중복 제거 ('title'과 'date'가 모두 동일한 경우 중복으로 간주)\n",
    "        combined_df.drop_duplicates(subset=['title', 'date'], keep='first', inplace=True)\n",
    "\n",
    "        # Excel 파일로 저장 (열 너비 자동 조정)\n",
    "        with pd.ExcelWriter(excel_file, engine='openpyxl') as writer:\n",
    "            combined_df.to_excel(writer, index=False, sheet_name='Sheet1')\n",
    "            workbook = writer.book\n",
    "            worksheet = writer.sheets['Sheet1']\n",
    "\n",
    "            # 각 열의 최대 길이를 계산하여 열 너비를 설정\n",
    "            for i, column in enumerate(combined_df.columns, 1):\n",
    "                # 열의 최대 길이 계산\n",
    "                max_length = combined_df[column].astype(str).map(len).max()\n",
    "                # 열 제목의 길이와 비교하여 더 큰 값 선택\n",
    "                max_length = max(max_length, len(column)) + 2  # 여유 공간 추가\n",
    "                # 열 번호를 열 문자로 변환\n",
    "                column_letter = get_column_letter(i)\n",
    "                # 열 너비 설정\n",
    "                worksheet.column_dimensions[column_letter].width = max_length\n",
    "\n",
    "        # 하이퍼링크 추가\n",
    "        wb = load_workbook(excel_file)\n",
    "        ws = wb['Sheet1']\n",
    "\n",
    "        # 'download_link'와 'preview_link' 컬럼 인덱스 찾기\n",
    "        download_col = combined_df.columns.get_loc('download_link') + 1\n",
    "        preview_col = combined_df.columns.get_loc('preview_link') + 1\n",
    "\n",
    "        # 하이퍼링크 설정\n",
    "        for row in range(2, len(combined_df) + 2):  # 헤더 제외\n",
    "            # 다운로드 링크 하이퍼링크 설정\n",
    "            download_cell = ws.cell(row=row, column=download_col)\n",
    "            if download_cell.value and isinstance(download_cell.value, str) and download_cell.value.startswith('http'):\n",
    "                download_cell.hyperlink = download_cell.value\n",
    "                download_cell.font = Font(color='0000FF', underline='single')\n",
    "\n",
    "            # 미리보기 링크 하이퍼링크 설정\n",
    "            preview_cell = ws.cell(row=row, column=preview_col)\n",
    "            if preview_cell.value and isinstance(preview_cell.value, str) and preview_cell.value.startswith('http'):\n",
    "                preview_cell.hyperlink = preview_cell.value\n",
    "                preview_cell.font = Font(color='0000FF', underline='single')\n",
    "\n",
    "        # 워크북 저장\n",
    "        wb.save(excel_file)\n",
    "\n",
    "        print(f\"\\n새로운 데이터 {len(new_df)}개를 수집하였습니다.\")\n",
    "        print(f\"중복을 제거한 후 총 {len(combined_df)}개의 데이터가 '{excel_file}'에 저장되었습니다.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"엑셀 파일 저장 중 오류 발생: {e}\")\n",
    "\n",
    "# 주피터 노트북에서 비동기 함수 실행\n",
    "await main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "https://seoulboard.seoul.go.kr/comm/getFile?srvcId=BBSTY1&upperNo=420057&fileTy=ATTACH&fileNo=2&bbsNo=158\n",
    "https://seoulboard.seoul.go.kr/comm/getFile?srvcId=BBSTY1&upperNo=420701&fileTy=ATTACH&fileNo=2&bbsNo=158"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
